{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SHL Internship.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "B58oTG_omqOV"
      },
      "source": [
        "#####################################################imports"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48SRv4hQmsYd",
        "outputId": "98d5bdfa-ee24-469f-d752-4df820ca421a"
      },
      "source": [
        "!pip install pandas"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqyTkXb0_Zc0"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "X = pd.read_csv('train.csv', sep=',', encoding='ISO-8859-1')\n",
        "y = X['evaluator_rating']\n",
        "X = X.dropna(axis=1)\n",
        "X = X.drop(columns=['Unnamed: 0', 'uniqueId','evaluator_rating'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "nJK38ObeAMDd",
        "outputId": "2b95bb38-a611-4c48-e626-87527a9b8491"
      },
      "source": [
        "X.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>promptId</th>\n",
              "      <th>essay</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>At present age, our education system is not go...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>I am agree the tightly defined curriculum of o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>I strongly agree with the statement that tight...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Our education system is nice quitely but i dis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>i am totally agree with the statement that tig...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   promptId                                              essay\n",
              "0         1  At present age, our education system is not go...\n",
              "1         1  I am agree the tightly defined curriculum of o...\n",
              "2         1  I strongly agree with the statement that tight...\n",
              "3         1  Our education system is nice quitely but i dis...\n",
              "4         1  i am totally agree with the statement that tig..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "X-YUv6dsR3JX",
        "outputId": "5676f485-d20d-4c2d-d57f-89ed41a44781"
      },
      "source": [
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>promptId</th>\n",
              "      <th>essay</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>At present age, our education system is not go...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>I am agree the tightly defined curriculum of o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>I strongly agree with the statement that tight...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Our education system is nice quitely but i dis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>i am totally agree with the statement that tig...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1235</th>\n",
              "      <td>5</td>\n",
              "      <td>The entire world is in the race of producing a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1236</th>\n",
              "      <td>5</td>\n",
              "      <td>The race in the development of weapons are pro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1237</th>\n",
              "      <td>5</td>\n",
              "      <td>In an era where every second person hopes and ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1238</th>\n",
              "      <td>5</td>\n",
              "      <td>INTRODUCTION :Since the beginning of the time ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1239</th>\n",
              "      <td>5</td>\n",
              "      <td>\"To conquer a nation, first disarm its citizen...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1240 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      promptId                                              essay\n",
              "0            1  At present age, our education system is not go...\n",
              "1            1  I am agree the tightly defined curriculum of o...\n",
              "2            1  I strongly agree with the statement that tight...\n",
              "3            1  Our education system is nice quitely but i dis...\n",
              "4            1  i am totally agree with the statement that tig...\n",
              "...        ...                                                ...\n",
              "1235         5  The entire world is in the race of producing a...\n",
              "1236         5  The race in the development of weapons are pro...\n",
              "1237         5  In an era where every second person hopes and ...\n",
              "1238         5  INTRODUCTION :Since the beginning of the time ...\n",
              "1239         5  \"To conquer a nation, first disarm its citizen...\n",
              "\n",
              "[1240 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HiTjMWL1wYA"
      },
      "source": [
        "######################################### Preprocessors and word2vec functions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJlRP_YyZUHv"
      },
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "def essay_to_wordlist(essay_v, remove_stopwords):\n",
        "    \"\"\"Remove the tagged labels and word tokenize the sentence.\"\"\"\n",
        "    essay_v = re.sub(\"[^a-zA-Z]\", \" \", essay_v)\n",
        "    words = essay_v.lower().split()\n",
        "    if remove_stopwords:\n",
        "        stops = set(stopwords.words(\"english\"))\n",
        "        words = [w for w in words if not w in stops]\n",
        "    return (words)\n",
        "\n",
        "def essay_to_sentences(essay_v, remove_stopwords):\n",
        "    \"\"\"Sentence tokenize the essay and call essay_to_wordlist() for word tokenization.\"\"\"\n",
        "    tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "    raw_sentences = tokenizer.tokenize(essay_v.strip())\n",
        "    sentences = []\n",
        "    for raw_sentence in raw_sentences:\n",
        "        if len(raw_sentence) > 0:\n",
        "            sentences.append(essay_to_wordlist(raw_sentence, remove_stopwords))\n",
        "    return sentences\n",
        "\n",
        "def makeFeatureVec(words, model, num_features):\n",
        "    \"\"\"Make Feature Vector from the words list of an Essay.\"\"\"\n",
        "    featureVec = np.zeros((num_features,),dtype=\"float32\")\n",
        "    num_words = 0.\n",
        "    index2word_set = set(model.wv.index2word)\n",
        "    for word in words:\n",
        "        if word in index2word_set:\n",
        "            num_words += 1\n",
        "            featureVec = np.add(featureVec,model[word])        \n",
        "    featureVec = np.divide(featureVec,num_words)\n",
        "    return featureVec\n",
        "\n",
        "def getAvgFeatureVecs(essays, model, num_features):\n",
        "    \"\"\"Main function to generate the word vectors for word2vec model.\"\"\"\n",
        "    counter = 0\n",
        "    essayFeatureVecs = np.zeros((len(essays),num_features),dtype=\"float32\")\n",
        "    for essay in essays:\n",
        "        essayFeatureVecs[counter] = makeFeatureVec(essay, model, num_features)\n",
        "        counter = counter + 1\n",
        "    return essayFeatureVecs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w35bZltzaKqr",
        "outputId": "ec647ff0-f290-48b7-94b9-f00dbd35b9ff"
      },
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMNiaeGq13D-"
      },
      "source": [
        "################### LSTM MODEL"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZmUMjuSaToz"
      },
      "source": [
        "from keras.layers import Embedding, LSTM, Dense, Dropout, Lambda, Flatten\n",
        "from keras.models import Sequential, load_model, model_from_config\n",
        "import keras.backend as K\n",
        "\n",
        "def get_model():\n",
        "    \"\"\"Define the model.\"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(300, dropout=0.4, recurrent_dropout=0.4, input_shape=[1, 300], return_sequences=True))\n",
        "    model.add(LSTM(64, recurrent_dropout=0.4))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='relu'))\n",
        "\n",
        "    model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['mae'])\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDjRrvhzA5re",
        "outputId": "97303a2f-14c8-4a99-e3d2-94b93a404d4c"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFEurlm6D9YV"
      },
      "source": [
        "minimum_scores = [0]*1240\n",
        "maximum_scores = [5]*1240"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7P99SgkezPX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrS-Gbjc18kI"
      },
      "source": [
        "########################## TRAIN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0gfyNbnaXPV",
        "outputId": "004b653e-4d78-466e-f448-31945aa9daa0"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "cv = KFold(n_splits = 5, shuffle = True)\n",
        "results = []\n",
        "y_pred_list = []\n",
        "y_test_list = []\n",
        "arr = [0]*248\n",
        "\n",
        "\n",
        "count = 1\n",
        "\n",
        "for traincv, testcv in cv.split(X):\n",
        "    print(\"\\n--------Fold {}--------\\n\".format(count))\n",
        "    X_test, X_train, y_test, y_train = X.iloc[testcv], X.iloc[traincv], y.iloc[testcv], y.iloc[traincv]\n",
        "    \n",
        "    train_essays = X_train['essay']\n",
        "    test_essays = X_test['essay']\n",
        "\n",
        "    sentences = []\n",
        "\n",
        "    y_test_list = [0]*248\n",
        "\n",
        "    for i in range(0,248):\n",
        "        y_test_list[i] = int(np.around(y_test.values[i]))\n",
        "\n",
        "    for essay in train_essays:\n",
        "         # Obtaining all sentences from the training essays.\n",
        "         sentences += essay_to_sentences(essay, remove_stopwords = True)\n",
        "            \n",
        "    # Initializing variables for word2vec model.\n",
        "    num_features = 300 \n",
        "    min_word_count = 40\n",
        "    num_workers = 4\n",
        "    context = 10\n",
        "    downsampling = 1e-3\n",
        "\n",
        "    print(\"Training Word2Vec Model...\")\n",
        "    model = Word2Vec(sentences, workers=num_workers, size=num_features, min_count = min_word_count, window = context, sample = downsampling)\n",
        "\n",
        "    model.init_sims(replace=True)\n",
        "    model.wv.save_word2vec_format('word2vecmodel.bin', binary=True)\n",
        "    clean_train_essays = []\n",
        "\n",
        "    # Generate training and testing data word vectors.\n",
        "    for essay_v in train_essays:\n",
        "        clean_train_essays.append(essay_to_wordlist(essay_v, remove_stopwords=True))\n",
        "    \n",
        "    trainDataVecs = getAvgFeatureVecs(clean_train_essays, model, num_features)\n",
        "\n",
        "    clean_test_essays = []\n",
        "    for essay_v in test_essays:\n",
        "        clean_test_essays.append(essay_to_wordlist( essay_v, remove_stopwords=True ))\n",
        "    testDataVecs = getAvgFeatureVecs( clean_test_essays, model, num_features )\n",
        "\n",
        "    trainDataVecs = np.array(trainDataVecs)\n",
        "    testDataVecs = np.array(testDataVecs)\n",
        "    # Reshaping train and test vectors to 3 dimensions. (1 represnts one timestep)\n",
        "    trainDataVecs = np.reshape(trainDataVecs, (trainDataVecs.shape[0], 1, trainDataVecs.shape[1]))\n",
        "    testDataVecs = np.reshape(testDataVecs, (testDataVecs.shape[0], 1, testDataVecs.shape[1]))\n",
        "\n",
        "    lstm_model = get_model()\n",
        "    lstm_model.fit(trainDataVecs, y_train, batch_size=64, epochs=2)\n",
        "    #lstm_model.load_weights('./model_weights/final_lstm.h5')\n",
        "    y_pred = lstm_model.predict(testDataVecs)\n",
        "    \n",
        "    print(y_pred)\n",
        "    \n",
        "    # Save models.\n",
        "    lstm_model.save('final_lstm%s.h5' %count)\n",
        "    \n",
        "    for i in range(0,248):\n",
        "        arr[i] = int(np.around(y_pred[i][0]))\n",
        "    \n",
        "\n",
        "    # Evaluate the model on the evaluation metric. \"Quadratic mean averaged Kappa\"\n",
        "    #result = cohen_kappa_score(y_test_list,arr,weights='quadratic')\n",
        "    print(\"Kappa Score: {}\".format(result))\n",
        "    #results.append(result)\n",
        "    y_pred_list = []\n",
        "    count += 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "--------Fold 1--------\n",
            "\n",
            "Training Word2Vec Model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_38 (LSTM)               (None, 1, 300)            721200    \n",
            "_________________________________________________________________\n",
            "lstm_39 (LSTM)               (None, 64)                93440     \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 814,705\n",
            "Trainable params: 814,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/2\n",
            "16/16 [==============================] - 7s 23ms/step - loss: 5.7361 - mae: 2.1181\n",
            "Epoch 2/2\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 1.2512 - mae: 0.8574\n",
            "[[2.7756655]\n",
            " [2.650485 ]\n",
            " [2.7978015]\n",
            " [2.9944186]\n",
            " [2.732912 ]\n",
            " [2.9487352]\n",
            " [2.8632255]\n",
            " [2.8354926]\n",
            " [2.5905924]\n",
            " [2.8987908]\n",
            " [2.7566776]\n",
            " [2.5192115]\n",
            " [2.809163 ]\n",
            " [2.8876536]\n",
            " [2.8539398]\n",
            " [2.844203 ]\n",
            " [2.9106343]\n",
            " [2.7450266]\n",
            " [2.8470607]\n",
            " [2.686652 ]\n",
            " [2.7035675]\n",
            " [2.7023354]\n",
            " [2.8993776]\n",
            " [2.7693276]\n",
            " [2.7477245]\n",
            " [2.6742218]\n",
            " [2.7365408]\n",
            " [2.8199353]\n",
            " [2.8133988]\n",
            " [2.7212992]\n",
            " [2.7513325]\n",
            " [2.8414602]\n",
            " [2.655784 ]\n",
            " [2.5615273]\n",
            " [2.5846162]\n",
            " [3.0021482]\n",
            " [2.7555757]\n",
            " [2.6562085]\n",
            " [2.7916832]\n",
            " [2.8090844]\n",
            " [2.7478747]\n",
            " [2.5622196]\n",
            " [2.8136806]\n",
            " [2.8803644]\n",
            " [2.7939506]\n",
            " [2.9240146]\n",
            " [2.8836322]\n",
            " [3.0036418]\n",
            " [2.786043 ]\n",
            " [2.667598 ]\n",
            " [2.6406112]\n",
            " [2.7760513]\n",
            " [2.7775743]\n",
            " [2.6419258]\n",
            " [2.75481  ]\n",
            " [2.7832026]\n",
            " [2.680262 ]\n",
            " [2.742043 ]\n",
            " [2.7104485]\n",
            " [2.7670572]\n",
            " [2.9563453]\n",
            " [2.8120244]\n",
            " [2.3216767]\n",
            " [2.0831265]\n",
            " [2.726318 ]\n",
            " [2.325191 ]\n",
            " [2.1462245]\n",
            " [2.4949079]\n",
            " [2.3882265]\n",
            " [2.4738526]\n",
            " [2.410233 ]\n",
            " [2.3533068]\n",
            " [2.4403791]\n",
            " [2.019767 ]\n",
            " [2.5521793]\n",
            " [2.8853638]\n",
            " [2.5109854]\n",
            " [2.4421225]\n",
            " [2.4642045]\n",
            " [2.5747616]\n",
            " [2.6300907]\n",
            " [2.51619  ]\n",
            " [2.4660654]\n",
            " [2.7208247]\n",
            " [2.6315246]\n",
            " [2.3433084]\n",
            " [2.5280633]\n",
            " [2.2965019]\n",
            " [2.5660353]\n",
            " [2.2769825]\n",
            " [2.5241842]\n",
            " [2.3434255]\n",
            " [2.5000095]\n",
            " [2.6250377]\n",
            " [2.1961849]\n",
            " [2.2244081]\n",
            " [2.1255698]\n",
            " [2.550905 ]\n",
            " [2.5172782]\n",
            " [2.5669541]\n",
            " [2.6872194]\n",
            " [2.477634 ]\n",
            " [2.4947624]\n",
            " [2.4458196]\n",
            " [2.4975803]\n",
            " [2.335266 ]\n",
            " [2.4519787]\n",
            " [2.4735591]\n",
            " [2.3885052]\n",
            " [2.642721 ]\n",
            " [2.8763204]\n",
            " [3.094934 ]\n",
            " [2.884865 ]\n",
            " [3.063328 ]\n",
            " [3.007648 ]\n",
            " [2.8917742]\n",
            " [2.970417 ]\n",
            " [3.0288854]\n",
            " [2.797583 ]\n",
            " [2.7744927]\n",
            " [3.0392275]\n",
            " [3.0223475]\n",
            " [2.8880966]\n",
            " [2.9734473]\n",
            " [2.9349627]\n",
            " [2.9314146]\n",
            " [2.9201198]\n",
            " [3.0158825]\n",
            " [3.105208 ]\n",
            " [3.0559025]\n",
            " [3.042228 ]\n",
            " [2.821189 ]\n",
            " [2.6690936]\n",
            " [2.8260274]\n",
            " [2.8809586]\n",
            " [2.9377737]\n",
            " [2.8249035]\n",
            " [2.860826 ]\n",
            " [2.9214194]\n",
            " [2.9798875]\n",
            " [2.92823  ]\n",
            " [2.9437943]\n",
            " [2.9852605]\n",
            " [2.942083 ]\n",
            " [2.825369 ]\n",
            " [2.8350105]\n",
            " [2.99487  ]\n",
            " [2.8805332]\n",
            " [3.0112376]\n",
            " [2.873261 ]\n",
            " [3.0823898]\n",
            " [2.971    ]\n",
            " [3.0242293]\n",
            " [2.9607766]\n",
            " [2.9551334]\n",
            " [2.9667406]\n",
            " [2.9421902]\n",
            " [2.9907508]\n",
            " [2.9820611]\n",
            " [3.0009334]\n",
            " [2.9602509]\n",
            " [2.92299  ]\n",
            " [2.9091527]\n",
            " [3.0448465]\n",
            " [3.0309668]\n",
            " [3.0451221]\n",
            " [2.9362211]\n",
            " [2.9190288]\n",
            " [3.0894766]\n",
            " [2.9391198]\n",
            " [2.9367695]\n",
            " [2.9084182]\n",
            " [2.9354491]\n",
            " [2.9870467]\n",
            " [2.8330975]\n",
            " [2.936997 ]\n",
            " [2.9007096]\n",
            " [2.8988729]\n",
            " [2.881719 ]\n",
            " [2.8904552]\n",
            " [2.8832908]\n",
            " [2.9935458]\n",
            " [2.8803658]\n",
            " [2.9491205]\n",
            " [2.310514 ]\n",
            " [2.3227913]\n",
            " [2.601029 ]\n",
            " [2.5960555]\n",
            " [2.5265803]\n",
            " [2.6025684]\n",
            " [2.6197138]\n",
            " [2.543941 ]\n",
            " [2.5958238]\n",
            " [2.4995513]\n",
            " [2.2447739]\n",
            " [2.5571828]\n",
            " [2.6938841]\n",
            " [2.444129 ]\n",
            " [2.5501416]\n",
            " [2.4942367]\n",
            " [2.5464745]\n",
            " [2.1557403]\n",
            " [2.785017 ]\n",
            " [2.4986296]\n",
            " [2.4776773]\n",
            " [2.2560916]\n",
            " [2.8848236]\n",
            " [2.332086 ]\n",
            " [2.284715 ]\n",
            " [2.449979 ]\n",
            " [2.4855504]\n",
            " [2.6597567]\n",
            " [2.338698 ]\n",
            " [2.6456394]\n",
            " [2.2954817]\n",
            " [2.324751 ]\n",
            " [2.5614233]\n",
            " [2.4463544]\n",
            " [2.5695224]\n",
            " [2.0821352]\n",
            " [2.6283898]\n",
            " [2.2981725]\n",
            " [2.3952208]\n",
            " [2.4865773]\n",
            " [2.3478003]\n",
            " [2.0621867]\n",
            " [2.709989 ]\n",
            " [2.5579762]\n",
            " [2.3778393]\n",
            " [2.2397914]\n",
            " [2.664126 ]\n",
            " [2.4601054]\n",
            " [2.5163   ]\n",
            " [2.4147396]\n",
            " [2.3279023]\n",
            " [2.6629775]\n",
            " [2.1998606]\n",
            " [2.5379634]\n",
            " [2.2274473]\n",
            " [2.0387588]\n",
            " [2.1740456]\n",
            " [2.5018106]\n",
            " [2.3556633]\n",
            " [2.4473643]\n",
            " [2.4288225]\n",
            " [2.560792 ]\n",
            " [2.487967 ]\n",
            " [2.6130073]]\n",
            "Kappa Score: 0.1765416127641224\n",
            "\n",
            "--------Fold 2--------\n",
            "\n",
            "Training Word2Vec Model...\n",
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_40 (LSTM)               (None, 1, 300)            721200    \n",
            "_________________________________________________________________\n",
            "lstm_41 (LSTM)               (None, 64)                93440     \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 814,705\n",
            "Trainable params: 814,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/2\n",
            "16/16 [==============================] - 8s 22ms/step - loss: 5.7215 - mae: 2.1265\n",
            "Epoch 2/2\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 1.2532 - mae: 0.8615\n",
            "[[3.0264683]\n",
            " [3.190927 ]\n",
            " [3.1775718]\n",
            " [2.9733238]\n",
            " [2.9740684]\n",
            " [3.0515437]\n",
            " [3.0888815]\n",
            " [3.1240044]\n",
            " [2.8830922]\n",
            " [3.0123515]\n",
            " [3.1155834]\n",
            " [2.9971852]\n",
            " [3.272976 ]\n",
            " [3.0782783]\n",
            " [2.8145342]\n",
            " [3.0853364]\n",
            " [3.0800703]\n",
            " [3.0538745]\n",
            " [3.062431 ]\n",
            " [3.2331939]\n",
            " [3.0856555]\n",
            " [3.2901812]\n",
            " [3.033726 ]\n",
            " [3.1697628]\n",
            " [3.0664744]\n",
            " [2.999585 ]\n",
            " [3.1419954]\n",
            " [3.1914644]\n",
            " [3.112732 ]\n",
            " [3.0768936]\n",
            " [2.987184 ]\n",
            " [3.173843 ]\n",
            " [2.8968196]\n",
            " [3.2911773]\n",
            " [3.0562215]\n",
            " [3.0602286]\n",
            " [3.3077884]\n",
            " [3.1117814]\n",
            " [3.0142298]\n",
            " [3.01087  ]\n",
            " [3.2592008]\n",
            " [2.6983857]\n",
            " [3.1333575]\n",
            " [3.224876 ]\n",
            " [3.0464115]\n",
            " [2.8232403]\n",
            " [3.1821175]\n",
            " [2.9127629]\n",
            " [3.2061958]\n",
            " [3.241064 ]\n",
            " [3.1818302]\n",
            " [3.0443413]\n",
            " [3.0755486]\n",
            " [3.1265354]\n",
            " [3.1067667]\n",
            " [2.909823 ]\n",
            " [3.1532288]\n",
            " [3.106022 ]\n",
            " [3.085731 ]\n",
            " [2.9366508]\n",
            " [3.0076275]\n",
            " [3.0124319]\n",
            " [2.6796045]\n",
            " [2.7541728]\n",
            " [2.9091196]\n",
            " [3.0067086]\n",
            " [2.8221118]\n",
            " [3.140122 ]\n",
            " [2.765798 ]\n",
            " [2.6165996]\n",
            " [2.89213  ]\n",
            " [2.9583917]\n",
            " [2.6586373]\n",
            " [2.73783  ]\n",
            " [2.8405414]\n",
            " [2.9081407]\n",
            " [2.8282042]\n",
            " [2.8545077]\n",
            " [2.8733916]\n",
            " [3.0082703]\n",
            " [2.6312642]\n",
            " [2.747745 ]\n",
            " [2.9625883]\n",
            " [2.9497313]\n",
            " [2.6347528]\n",
            " [2.454206 ]\n",
            " [2.3240914]\n",
            " [2.6007986]\n",
            " [2.6579823]\n",
            " [2.8019743]\n",
            " [2.7612972]\n",
            " [2.6799896]\n",
            " [2.5927734]\n",
            " [3.0093603]\n",
            " [3.0636792]\n",
            " [2.6297388]\n",
            " [2.8126416]\n",
            " [3.0137424]\n",
            " [2.8144848]\n",
            " [2.64743  ]\n",
            " [2.6451683]\n",
            " [2.9626393]\n",
            " [2.7597532]\n",
            " [3.001585 ]\n",
            " [2.7923338]\n",
            " [2.9198494]\n",
            " [2.835726 ]\n",
            " [2.665415 ]\n",
            " [2.9798756]\n",
            " [2.7206635]\n",
            " [3.1338167]\n",
            " [3.482728 ]\n",
            " [3.2648242]\n",
            " [3.4137452]\n",
            " [3.4428072]\n",
            " [3.25089  ]\n",
            " [3.3692656]\n",
            " [3.3576097]\n",
            " [3.2705257]\n",
            " [3.3967085]\n",
            " [3.344781 ]\n",
            " [3.3589616]\n",
            " [3.292468 ]\n",
            " [3.2310557]\n",
            " [3.39815  ]\n",
            " [3.4289963]\n",
            " [3.3391724]\n",
            " [3.3928099]\n",
            " [3.301139 ]\n",
            " [3.4394774]\n",
            " [3.1890035]\n",
            " [3.1299   ]\n",
            " [3.3637297]\n",
            " [3.3313646]\n",
            " [3.1781037]\n",
            " [3.477194 ]\n",
            " [3.176824 ]\n",
            " [3.435793 ]\n",
            " [3.3901684]\n",
            " [3.2453775]\n",
            " [3.3411152]\n",
            " [3.2358737]\n",
            " [3.440754 ]\n",
            " [3.3032048]\n",
            " [3.243372 ]\n",
            " [3.2848206]\n",
            " [3.1542475]\n",
            " [3.4110482]\n",
            " [3.5316281]\n",
            " [3.2865765]\n",
            " [3.3489091]\n",
            " [3.353397 ]\n",
            " [3.4360223]\n",
            " [3.3007827]\n",
            " [3.208612 ]\n",
            " [3.377593 ]\n",
            " [3.3935497]\n",
            " [3.407383 ]\n",
            " [3.3465312]\n",
            " [3.3023746]\n",
            " [3.347296 ]\n",
            " [3.2460132]\n",
            " [3.18607  ]\n",
            " [3.446122 ]\n",
            " [3.3716269]\n",
            " [3.2100515]\n",
            " [3.3430843]\n",
            " [3.1759276]\n",
            " [3.3193042]\n",
            " [3.417313 ]\n",
            " [3.2966774]\n",
            " [3.0960388]\n",
            " [3.4206917]\n",
            " [3.2653384]\n",
            " [3.2802174]\n",
            " [3.3982725]\n",
            " [3.3714118]\n",
            " [3.0843449]\n",
            " [3.2972956]\n",
            " [3.2920651]\n",
            " [3.346373 ]\n",
            " [3.3225489]\n",
            " [3.4054713]\n",
            " [3.1024883]\n",
            " [3.2758732]\n",
            " [3.4125996]\n",
            " [3.3540533]\n",
            " [3.4471126]\n",
            " [3.2644806]\n",
            " [3.136584 ]\n",
            " [2.7567847]\n",
            " [2.482021 ]\n",
            " [3.443417 ]\n",
            " [3.270235 ]\n",
            " [2.665654 ]\n",
            " [2.8271453]\n",
            " [2.8322701]\n",
            " [2.8112228]\n",
            " [2.7973619]\n",
            " [3.0090156]\n",
            " [2.8039114]\n",
            " [2.569261 ]\n",
            " [2.4751081]\n",
            " [2.7473202]\n",
            " [2.8122854]\n",
            " [2.7792563]\n",
            " [2.3194826]\n",
            " [2.7594898]\n",
            " [2.9863002]\n",
            " [2.715353 ]\n",
            " [2.789428 ]\n",
            " [2.7441258]\n",
            " [3.0411558]\n",
            " [2.83537  ]\n",
            " [2.9632857]\n",
            " [2.5824668]\n",
            " [2.9006915]\n",
            " [2.2378159]\n",
            " [3.186429 ]\n",
            " [3.0417483]\n",
            " [3.141852 ]\n",
            " [2.6860342]\n",
            " [2.865622 ]\n",
            " [2.6045184]\n",
            " [3.100344 ]\n",
            " [3.0752587]\n",
            " [2.769152 ]\n",
            " [2.6743922]\n",
            " [2.9750085]\n",
            " [2.8329058]\n",
            " [2.6643524]\n",
            " [2.541975 ]\n",
            " [2.9137478]\n",
            " [2.5738277]\n",
            " [2.777268 ]\n",
            " [2.7638397]\n",
            " [2.5757537]\n",
            " [3.024723 ]\n",
            " [2.6310844]\n",
            " [2.8856034]\n",
            " [2.9206975]\n",
            " [2.8286695]\n",
            " [2.9684854]\n",
            " [2.9240532]\n",
            " [2.7854528]\n",
            " [2.852803 ]\n",
            " [2.8142095]\n",
            " [2.6885214]]\n",
            "Kappa Score: 0.1765416127641224\n",
            "\n",
            "--------Fold 3--------\n",
            "\n",
            "Training Word2Vec Model...\n",
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_42 (LSTM)               (None, 1, 300)            721200    \n",
            "_________________________________________________________________\n",
            "lstm_43 (LSTM)               (None, 64)                93440     \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 814,705\n",
            "Trainable params: 814,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/2\n",
            "16/16 [==============================] - 8s 23ms/step - loss: 5.8683 - mae: 2.1818\n",
            "Epoch 2/2\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 1.1654 - mae: 0.8293\n",
            "[[3.0386438]\n",
            " [3.0587583]\n",
            " [2.8371658]\n",
            " [2.6835134]\n",
            " [2.9731083]\n",
            " [2.8913736]\n",
            " [3.0728376]\n",
            " [2.6960578]\n",
            " [2.8793685]\n",
            " [2.9379191]\n",
            " [2.6663773]\n",
            " [2.9180987]\n",
            " [2.260437 ]\n",
            " [2.6186419]\n",
            " [2.802728 ]\n",
            " [2.9598954]\n",
            " [2.9710622]\n",
            " [2.7562559]\n",
            " [2.8855765]\n",
            " [2.6060662]\n",
            " [2.8904524]\n",
            " [2.9712315]\n",
            " [2.6805804]\n",
            " [3.025293 ]\n",
            " [2.9938302]\n",
            " [2.7956436]\n",
            " [2.9978895]\n",
            " [2.753295 ]\n",
            " [2.836585 ]\n",
            " [2.7909086]\n",
            " [3.0852466]\n",
            " [2.5757139]\n",
            " [2.9430053]\n",
            " [2.8889632]\n",
            " [2.950953 ]\n",
            " [2.9091334]\n",
            " [2.9545598]\n",
            " [3.070004 ]\n",
            " [2.8786511]\n",
            " [2.7002413]\n",
            " [3.0548322]\n",
            " [2.618321 ]\n",
            " [2.6199117]\n",
            " [2.9416776]\n",
            " [2.4733696]\n",
            " [2.450139 ]\n",
            " [2.521182 ]\n",
            " [2.5308485]\n",
            " [2.5063496]\n",
            " [2.5469127]\n",
            " [2.6976554]\n",
            " [2.4773362]\n",
            " [2.6574705]\n",
            " [2.7574046]\n",
            " [2.4830525]\n",
            " [2.6411989]\n",
            " [2.7530625]\n",
            " [2.6002774]\n",
            " [2.2606065]\n",
            " [2.855311 ]\n",
            " [2.6338866]\n",
            " [2.828    ]\n",
            " [2.3948188]\n",
            " [2.570665 ]\n",
            " [2.5349345]\n",
            " [2.6157062]\n",
            " [2.514835 ]\n",
            " [2.6864088]\n",
            " [2.7155151]\n",
            " [2.2974966]\n",
            " [2.5818377]\n",
            " [2.6250453]\n",
            " [2.7122123]\n",
            " [2.683705 ]\n",
            " [2.88662  ]\n",
            " [3.0865357]\n",
            " [2.6276474]\n",
            " [2.6440237]\n",
            " [2.7472658]\n",
            " [2.4782157]\n",
            " [2.735108 ]\n",
            " [2.4773598]\n",
            " [2.4600182]\n",
            " [2.9507608]\n",
            " [2.7064068]\n",
            " [2.5467992]\n",
            " [2.8413928]\n",
            " [2.9812586]\n",
            " [2.5477223]\n",
            " [2.7137165]\n",
            " [2.5121524]\n",
            " [2.2887523]\n",
            " [2.6702995]\n",
            " [2.7245946]\n",
            " [2.705933 ]\n",
            " [2.9620252]\n",
            " [3.0538802]\n",
            " [2.5988317]\n",
            " [2.724988 ]\n",
            " [2.6320906]\n",
            " [2.5101514]\n",
            " [2.4751897]\n",
            " [2.497528 ]\n",
            " [2.4055207]\n",
            " [2.6479218]\n",
            " [2.221818 ]\n",
            " [2.57695  ]\n",
            " [2.6579266]\n",
            " [2.5639687]\n",
            " [2.6605654]\n",
            " [2.7660828]\n",
            " [2.7368793]\n",
            " [2.4909918]\n",
            " [3.044597 ]\n",
            " [3.1741552]\n",
            " [3.2270741]\n",
            " [3.0977967]\n",
            " [3.0908608]\n",
            " [3.086379 ]\n",
            " [3.1867652]\n",
            " [3.087409 ]\n",
            " [3.1736016]\n",
            " [3.054718 ]\n",
            " [3.0747948]\n",
            " [3.1944704]\n",
            " [3.209828 ]\n",
            " [3.1950905]\n",
            " [3.1061978]\n",
            " [3.1826432]\n",
            " [3.1531878]\n",
            " [3.1333318]\n",
            " [3.019349 ]\n",
            " [3.0346406]\n",
            " [3.135081 ]\n",
            " [3.1391916]\n",
            " [2.8764112]\n",
            " [3.1446137]\n",
            " [3.0415154]\n",
            " [3.1557555]\n",
            " [3.0505533]\n",
            " [3.124445 ]\n",
            " [3.2474792]\n",
            " [3.0420377]\n",
            " [3.1394434]\n",
            " [3.0267625]\n",
            " [3.0256114]\n",
            " [3.1185665]\n",
            " [3.1102152]\n",
            " [3.0476365]\n",
            " [3.1869512]\n",
            " [3.1773827]\n",
            " [3.0674605]\n",
            " [2.915621 ]\n",
            " [3.055193 ]\n",
            " [3.0659409]\n",
            " [3.0431933]\n",
            " [3.106845 ]\n",
            " [3.1117556]\n",
            " [3.170793 ]\n",
            " [3.1726696]\n",
            " [3.155609 ]\n",
            " [2.8588288]\n",
            " [3.0073576]\n",
            " [2.9612765]\n",
            " [3.239204 ]\n",
            " [3.2227144]\n",
            " [3.0830917]\n",
            " [3.1746874]\n",
            " [3.0109909]\n",
            " [3.2013345]\n",
            " [3.112967 ]\n",
            " [3.1870246]\n",
            " [3.1444368]\n",
            " [3.1713662]\n",
            " [3.2502904]\n",
            " [3.0703158]\n",
            " [2.9148273]\n",
            " [2.1689367]\n",
            " [2.811533 ]\n",
            " [2.38414  ]\n",
            " [3.038928 ]\n",
            " [2.81745  ]\n",
            " [2.670927 ]\n",
            " [2.9605913]\n",
            " [2.7573025]\n",
            " [2.6896317]\n",
            " [2.0973125]\n",
            " [2.474826 ]\n",
            " [2.9553432]\n",
            " [2.419779 ]\n",
            " [2.506918 ]\n",
            " [2.7036438]\n",
            " [2.6702554]\n",
            " [2.8546128]\n",
            " [2.73275  ]\n",
            " [2.5048728]\n",
            " [2.3332253]\n",
            " [2.8153422]\n",
            " [2.7729332]\n",
            " [2.769059 ]\n",
            " [2.345679 ]\n",
            " [2.9400327]\n",
            " [2.8766463]\n",
            " [2.4133759]\n",
            " [2.9249597]\n",
            " [2.367485 ]\n",
            " [2.8162363]\n",
            " [3.1271782]\n",
            " [2.7305088]\n",
            " [2.550034 ]\n",
            " [2.9564734]\n",
            " [2.556242 ]\n",
            " [2.5404541]\n",
            " [2.795475 ]\n",
            " [2.848158 ]\n",
            " [2.6701531]\n",
            " [2.9249477]\n",
            " [2.776258 ]\n",
            " [2.5848927]\n",
            " [2.5611386]\n",
            " [2.7907796]\n",
            " [2.395462 ]\n",
            " [2.2906942]\n",
            " [2.6395938]\n",
            " [2.6970558]\n",
            " [2.7954097]\n",
            " [2.8150718]\n",
            " [2.689333 ]\n",
            " [2.872242 ]\n",
            " [2.7718625]\n",
            " [2.8052492]\n",
            " [2.6011188]\n",
            " [2.4986572]\n",
            " [2.5196154]\n",
            " [2.589075 ]\n",
            " [2.5563178]\n",
            " [2.4767182]\n",
            " [2.9217224]\n",
            " [2.6653323]\n",
            " [2.7821727]\n",
            " [2.2843268]\n",
            " [2.7358537]\n",
            " [2.920715 ]\n",
            " [2.7764983]\n",
            " [2.7209377]\n",
            " [3.0581489]\n",
            " [2.6414878]\n",
            " [2.8978195]]\n",
            "Kappa Score: 0.1765416127641224\n",
            "\n",
            "--------Fold 4--------\n",
            "\n",
            "Training Word2Vec Model...\n",
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_44 (LSTM)               (None, 1, 300)            721200    \n",
            "_________________________________________________________________\n",
            "lstm_45 (LSTM)               (None, 64)                93440     \n",
            "_________________________________________________________________\n",
            "dropout_22 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 814,705\n",
            "Trainable params: 814,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/2\n",
            "16/16 [==============================] - 8s 23ms/step - loss: 5.7820 - mae: 2.1304\n",
            "Epoch 2/2\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 1.2394 - mae: 0.8556\n",
            "[[3.1096315]\n",
            " [2.967839 ]\n",
            " [2.8882053]\n",
            " [2.8108134]\n",
            " [2.9473217]\n",
            " [3.0503848]\n",
            " [2.9471226]\n",
            " [3.266646 ]\n",
            " [3.1563692]\n",
            " [2.9515848]\n",
            " [2.7162673]\n",
            " [2.952918 ]\n",
            " [2.8321683]\n",
            " [2.8174376]\n",
            " [2.9916139]\n",
            " [3.2297802]\n",
            " [3.1897893]\n",
            " [3.130033 ]\n",
            " [3.0453598]\n",
            " [3.0529263]\n",
            " [3.1177113]\n",
            " [3.012593 ]\n",
            " [2.9471297]\n",
            " [3.159416 ]\n",
            " [3.0343251]\n",
            " [3.2012901]\n",
            " [2.8864145]\n",
            " [2.8883252]\n",
            " [2.8545651]\n",
            " [2.9614637]\n",
            " [3.036491 ]\n",
            " [2.8284268]\n",
            " [3.1740074]\n",
            " [3.055536 ]\n",
            " [3.1704903]\n",
            " [2.7814128]\n",
            " [3.0479963]\n",
            " [2.7401717]\n",
            " [2.8806224]\n",
            " [2.7421765]\n",
            " [2.8564758]\n",
            " [3.1122918]\n",
            " [2.9293015]\n",
            " [2.838513 ]\n",
            " [2.7975497]\n",
            " [3.0028653]\n",
            " [2.8800573]\n",
            " [3.22411  ]\n",
            " [2.9848533]\n",
            " [3.0684617]\n",
            " [2.939011 ]\n",
            " [2.7957344]\n",
            " [3.1026082]\n",
            " [2.9046996]\n",
            " [2.7093644]\n",
            " [2.566461 ]\n",
            " [2.415852 ]\n",
            " [2.628704 ]\n",
            " [2.7844734]\n",
            " [2.7540343]\n",
            " [2.5096092]\n",
            " [2.5186586]\n",
            " [2.8625007]\n",
            " [2.6513171]\n",
            " [2.8059764]\n",
            " [2.7330947]\n",
            " [2.8760295]\n",
            " [2.3278966]\n",
            " [2.9914813]\n",
            " [2.773636 ]\n",
            " [2.5801704]\n",
            " [2.5145636]\n",
            " [2.7896903]\n",
            " [2.762237 ]\n",
            " [2.9076848]\n",
            " [2.95144  ]\n",
            " [2.6559625]\n",
            " [2.7937012]\n",
            " [2.782611 ]\n",
            " [2.6722915]\n",
            " [2.8138576]\n",
            " [2.6605582]\n",
            " [2.8406293]\n",
            " [2.3879938]\n",
            " [3.0722985]\n",
            " [3.024383 ]\n",
            " [2.6531982]\n",
            " [2.926028 ]\n",
            " [2.772632 ]\n",
            " [2.8425403]\n",
            " [2.8817527]\n",
            " [2.3661761]\n",
            " [3.1188498]\n",
            " [2.8323765]\n",
            " [3.0227022]\n",
            " [2.867784 ]\n",
            " [2.9340997]\n",
            " [2.5600057]\n",
            " [2.6536038]\n",
            " [2.9852765]\n",
            " [2.9262757]\n",
            " [2.627512 ]\n",
            " [2.9665318]\n",
            " [2.5501966]\n",
            " [2.8978548]\n",
            " [2.407227 ]\n",
            " [2.677116 ]\n",
            " [2.7808456]\n",
            " [2.780439 ]\n",
            " [2.7870593]\n",
            " [2.5700967]\n",
            " [2.6294556]\n",
            " [2.657545 ]\n",
            " [2.7372336]\n",
            " [2.5720832]\n",
            " [2.7810762]\n",
            " [3.0439641]\n",
            " [2.3260522]\n",
            " [2.6864934]\n",
            " [2.3930054]\n",
            " [2.67728  ]\n",
            " [2.7987409]\n",
            " [2.5596855]\n",
            " [2.9109712]\n",
            " [3.0340965]\n",
            " [2.8314574]\n",
            " [2.3534856]\n",
            " [2.67562  ]\n",
            " [2.854491 ]\n",
            " [2.786666 ]\n",
            " [2.4991617]\n",
            " [2.6248574]\n",
            " [2.7195673]\n",
            " [3.1677394]\n",
            " [3.114537 ]\n",
            " [3.3020048]\n",
            " [3.2438824]\n",
            " [3.2472308]\n",
            " [3.2189407]\n",
            " [3.2629542]\n",
            " [3.2040882]\n",
            " [3.169596 ]\n",
            " [3.2837243]\n",
            " [3.0666337]\n",
            " [3.1335204]\n",
            " [3.2189934]\n",
            " [3.2233992]\n",
            " [3.196166 ]\n",
            " [3.1871667]\n",
            " [3.3124847]\n",
            " [3.073813 ]\n",
            " [3.2289762]\n",
            " [3.1478553]\n",
            " [3.180006 ]\n",
            " [3.2967062]\n",
            " [3.2637045]\n",
            " [3.2086992]\n",
            " [3.1691923]\n",
            " [3.3136823]\n",
            " [3.1866813]\n",
            " [3.0531573]\n",
            " [3.1378212]\n",
            " [3.1168137]\n",
            " [3.1585488]\n",
            " [3.2208223]\n",
            " [3.355196 ]\n",
            " [3.1996312]\n",
            " [3.324141 ]\n",
            " [3.2744782]\n",
            " [3.2683945]\n",
            " [3.2545602]\n",
            " [3.2497506]\n",
            " [3.1959476]\n",
            " [3.2302468]\n",
            " [3.318803 ]\n",
            " [3.2819076]\n",
            " [3.130323 ]\n",
            " [3.2130222]\n",
            " [3.0274758]\n",
            " [3.2948928]\n",
            " [3.2513835]\n",
            " [3.1883285]\n",
            " [3.2333972]\n",
            " [3.2253714]\n",
            " [3.252864 ]\n",
            " [3.112796 ]\n",
            " [3.285917 ]\n",
            " [2.6128163]\n",
            " [2.559216 ]\n",
            " [2.590034 ]\n",
            " [2.8028264]\n",
            " [2.1889038]\n",
            " [2.4554467]\n",
            " [3.0600271]\n",
            " [2.8428833]\n",
            " [2.7135396]\n",
            " [2.5059094]\n",
            " [2.7415867]\n",
            " [2.5967631]\n",
            " [2.444595 ]\n",
            " [2.7505805]\n",
            " [3.0107183]\n",
            " [2.7753944]\n",
            " [2.5539982]\n",
            " [2.7665536]\n",
            " [2.6325035]\n",
            " [2.7308269]\n",
            " [2.02915  ]\n",
            " [2.7617774]\n",
            " [2.4741554]\n",
            " [2.902563 ]\n",
            " [2.525273 ]\n",
            " [2.8007913]\n",
            " [2.7473764]\n",
            " [2.8137388]\n",
            " [2.4226923]\n",
            " [2.9388895]\n",
            " [2.6857085]\n",
            " [2.7155237]\n",
            " [2.8910418]\n",
            " [2.9898574]\n",
            " [2.7692227]\n",
            " [2.3610764]\n",
            " [3.0661228]\n",
            " [2.6285343]\n",
            " [2.6382241]\n",
            " [2.1510434]\n",
            " [2.9104276]\n",
            " [2.4279914]\n",
            " [2.7888875]\n",
            " [2.9429169]\n",
            " [2.6765184]\n",
            " [2.6184042]\n",
            " [2.8329997]\n",
            " [2.7337122]\n",
            " [2.4804735]\n",
            " [2.7979891]\n",
            " [3.0336103]\n",
            " [3.0529141]\n",
            " [2.6890113]\n",
            " [2.8765864]\n",
            " [2.5805068]\n",
            " [2.7066011]\n",
            " [2.75951  ]\n",
            " [2.8326054]\n",
            " [2.401297 ]\n",
            " [2.5545716]\n",
            " [2.9284177]]\n",
            "Kappa Score: 0.1765416127641224\n",
            "\n",
            "--------Fold 5--------\n",
            "\n",
            "Training Word2Vec Model...\n",
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_46 (LSTM)               (None, 1, 300)            721200    \n",
            "_________________________________________________________________\n",
            "lstm_47 (LSTM)               (None, 64)                93440     \n",
            "_________________________________________________________________\n",
            "dropout_23 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 814,705\n",
            "Trainable params: 814,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/2\n",
            "16/16 [==============================] - 7s 23ms/step - loss: 5.8860 - mae: 2.1376\n",
            "Epoch 2/2\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 1.2682 - mae: 0.8392\n",
            "[[2.6917236]\n",
            " [2.851282 ]\n",
            " [2.6975417]\n",
            " [2.7910302]\n",
            " [2.657488 ]\n",
            " [2.777757 ]\n",
            " [2.9558902]\n",
            " [2.8492959]\n",
            " [2.713898 ]\n",
            " [2.782021 ]\n",
            " [2.8382285]\n",
            " [2.710849 ]\n",
            " [2.6924326]\n",
            " [2.8405166]\n",
            " [2.7693925]\n",
            " [2.6804087]\n",
            " [2.7100563]\n",
            " [2.746057 ]\n",
            " [2.3215313]\n",
            " [2.6746244]\n",
            " [2.489652 ]\n",
            " [2.786851 ]\n",
            " [2.7053666]\n",
            " [2.6842315]\n",
            " [2.6286514]\n",
            " [2.5236185]\n",
            " [2.6438515]\n",
            " [2.6672976]\n",
            " [2.7853956]\n",
            " [2.7565348]\n",
            " [2.643008 ]\n",
            " [2.6323218]\n",
            " [2.7060673]\n",
            " [2.604035 ]\n",
            " [2.794631 ]\n",
            " [2.647149 ]\n",
            " [2.6765258]\n",
            " [2.759173 ]\n",
            " [2.7985208]\n",
            " [2.6341298]\n",
            " [2.4967008]\n",
            " [2.6918652]\n",
            " [2.7693367]\n",
            " [2.7352154]\n",
            " [2.724192 ]\n",
            " [2.728329 ]\n",
            " [2.8775961]\n",
            " [2.7795036]\n",
            " [2.6655655]\n",
            " [2.8300424]\n",
            " [2.6367762]\n",
            " [2.789962 ]\n",
            " [2.7012808]\n",
            " [2.7026646]\n",
            " [2.511521 ]\n",
            " [2.2913   ]\n",
            " [2.7126594]\n",
            " [2.3929703]\n",
            " [2.442989 ]\n",
            " [2.217735 ]\n",
            " [2.4123933]\n",
            " [2.631276 ]\n",
            " [2.370579 ]\n",
            " [2.2556784]\n",
            " [2.759815 ]\n",
            " [2.3355439]\n",
            " [2.6768987]\n",
            " [2.4983075]\n",
            " [2.2443495]\n",
            " [2.1083086]\n",
            " [2.3293831]\n",
            " [2.422816 ]\n",
            " [2.1356866]\n",
            " [2.5884113]\n",
            " [2.3479846]\n",
            " [2.475046 ]\n",
            " [2.4541426]\n",
            " [2.2583487]\n",
            " [2.5924482]\n",
            " [2.465306 ]\n",
            " [2.5840485]\n",
            " [2.4985135]\n",
            " [2.55741  ]\n",
            " [2.4489908]\n",
            " [2.51967  ]\n",
            " [2.75792  ]\n",
            " [2.4310253]\n",
            " [2.4877756]\n",
            " [2.7114887]\n",
            " [2.424278 ]\n",
            " [2.4877336]\n",
            " [2.5615885]\n",
            " [2.7558224]\n",
            " [2.5676205]\n",
            " [2.213489 ]\n",
            " [1.9668063]\n",
            " [2.0985255]\n",
            " [2.1348398]\n",
            " [2.7547548]\n",
            " [2.4567602]\n",
            " [2.418421 ]\n",
            " [2.449283 ]\n",
            " [2.2582693]\n",
            " [2.3767326]\n",
            " [2.0174515]\n",
            " [2.6052   ]\n",
            " [2.571058 ]\n",
            " [2.5414522]\n",
            " [2.3900895]\n",
            " [2.634272 ]\n",
            " [2.573078 ]\n",
            " [2.583763 ]\n",
            " [2.503155 ]\n",
            " [2.257521 ]\n",
            " [2.5099666]\n",
            " [2.1486192]\n",
            " [2.2648947]\n",
            " [2.5593202]\n",
            " [2.6190503]\n",
            " [2.4576826]\n",
            " [2.5140507]\n",
            " [2.643048 ]\n",
            " [3.017653 ]\n",
            " [2.86279  ]\n",
            " [2.7253182]\n",
            " [2.942426 ]\n",
            " [2.8833354]\n",
            " [2.754392 ]\n",
            " [2.9152248]\n",
            " [3.0941787]\n",
            " [3.0208163]\n",
            " [2.7713153]\n",
            " [2.7001612]\n",
            " [2.8162692]\n",
            " [2.9116666]\n",
            " [3.0097675]\n",
            " [2.8307683]\n",
            " [2.92307  ]\n",
            " [2.957682 ]\n",
            " [2.9372685]\n",
            " [2.8292158]\n",
            " [2.9591525]\n",
            " [3.0902846]\n",
            " [2.8707707]\n",
            " [2.9898055]\n",
            " [2.9360151]\n",
            " [2.8536744]\n",
            " [2.9636824]\n",
            " [3.0199206]\n",
            " [2.9207122]\n",
            " [2.9363637]\n",
            " [2.9480565]\n",
            " [2.6059387]\n",
            " [2.9438274]\n",
            " [2.9168625]\n",
            " [2.9273255]\n",
            " [3.0309727]\n",
            " [2.9236138]\n",
            " [2.8746974]\n",
            " [2.889586 ]\n",
            " [2.8022666]\n",
            " [2.9420092]\n",
            " [2.9062023]\n",
            " [2.938164 ]\n",
            " [2.9238038]\n",
            " [2.9775436]\n",
            " [2.9557383]\n",
            " [3.174268 ]\n",
            " [2.9589665]\n",
            " [2.90812  ]\n",
            " [2.992049 ]\n",
            " [2.9262736]\n",
            " [2.9401722]\n",
            " [2.8438494]\n",
            " [2.9496534]\n",
            " [2.7732084]\n",
            " [2.903035 ]\n",
            " [2.5953257]\n",
            " [2.5665169]\n",
            " [2.7607033]\n",
            " [2.3237092]\n",
            " [2.3053908]\n",
            " [2.6285336]\n",
            " [2.287009 ]\n",
            " [2.3297334]\n",
            " [2.7425396]\n",
            " [2.0684848]\n",
            " [2.3602083]\n",
            " [2.3581908]\n",
            " [2.382936 ]\n",
            " [2.2167099]\n",
            " [2.609863 ]\n",
            " [2.487929 ]\n",
            " [2.3238988]\n",
            " [2.41277  ]\n",
            " [2.614995 ]\n",
            " [2.4221013]\n",
            " [2.4667287]\n",
            " [2.4569576]\n",
            " [2.649393 ]\n",
            " [2.1977098]\n",
            " [2.5266628]\n",
            " [2.4880657]\n",
            " [1.982104 ]\n",
            " [2.613292 ]\n",
            " [2.452347 ]\n",
            " [2.3725975]\n",
            " [2.6604893]\n",
            " [2.4583032]\n",
            " [2.152138 ]\n",
            " [2.13445  ]\n",
            " [2.234742 ]\n",
            " [2.3317893]\n",
            " [2.3304424]\n",
            " [2.0984976]\n",
            " [2.1480482]\n",
            " [2.3654249]\n",
            " [2.5663493]\n",
            " [2.0252583]\n",
            " [2.455161 ]\n",
            " [2.1634767]\n",
            " [2.2982514]\n",
            " [2.576031 ]\n",
            " [2.4569042]\n",
            " [2.1311052]\n",
            " [2.457002 ]\n",
            " [2.4100099]\n",
            " [2.490936 ]\n",
            " [2.6141675]\n",
            " [2.55064  ]\n",
            " [2.4599724]\n",
            " [2.3344612]\n",
            " [2.0758247]\n",
            " [2.4665315]\n",
            " [2.5010443]\n",
            " [2.1683488]\n",
            " [2.3377717]\n",
            " [2.312228 ]\n",
            " [2.149125 ]\n",
            " [1.9994614]\n",
            " [2.5841408]\n",
            " [2.6556907]\n",
            " [2.42897  ]\n",
            " [2.3855464]\n",
            " [2.2690334]\n",
            " [2.8184874]\n",
            " [2.5078967]\n",
            " [2.603786 ]]\n",
            "Kappa Score: 0.1765416127641224\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDaoBLbYgmpY"
      },
      "source": [
        "################################ inference"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZJaocVdxAFF"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "X = pd.read_csv('test.csv', sep=',', encoding='ISO-8859-1')\n",
        "#y = X['evaluator_rating']\n",
        "X = X.dropna(axis=1)\n",
        "X = X.drop(columns=['Unnamed: 0', 'uniqueId'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_niu8I-2TKt",
        "outputId": "7c61b929-13e8-4bfd-9845-8718c065b24e"
      },
      "source": [
        "X.essay"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      Curriculum has been adopted in many schools. T...\n",
              "1      I strongly agree with the statement ,  The tig...\n",
              "2      Imagination and creativity is the most importa...\n",
              "3      In our eduction system leaves no room for imag...\n",
              "4      I will agree at some what extend, because if w...\n",
              "                             ...                        \n",
              "300    Earth is a creation of God and everything that...\n",
              "301    production of arms and weapons in this present...\n",
              "302    Race to become more powerful can destroy the e...\n",
              "303    In its attempt to harness the power of the ato...\n",
              "304    Racein the production of arms and weapons in t...\n",
              "Name: essay, Length: 305, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqaVZT3WIuCG"
      },
      "source": [
        "cv = KFold(n_splits = 5, shuffle = True)\n",
        "\n",
        "\n",
        "#X_train = X.iloc[traincv]\n",
        "    \n",
        "train_essays = X['essay']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImT2zaPtJBKT",
        "outputId": "a44bbc3d-3162-4c44-daf8-3bdc6eeae592"
      },
      "source": [
        "train_essays"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      Curriculum has been adopted in many schools. T...\n",
              "1      I strongly agree with the statement ,  The tig...\n",
              "2      Imagination and creativity is the most importa...\n",
              "3      In our eduction system leaves no room for imag...\n",
              "4      I will agree at some what extend, because if w...\n",
              "                             ...                        \n",
              "300    Earth is a creation of God and everything that...\n",
              "301    production of arms and weapons in this present...\n",
              "302    Race to become more powerful can destroy the e...\n",
              "303    In its attempt to harness the power of the ato...\n",
              "304    Racein the production of arms and weapons in t...\n",
              "Name: essay, Length: 305, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "evZdcFRNSVts",
        "outputId": "dd1d937d-b27e-4c27-9546-c3c91cf1972c"
      },
      "source": [
        "X['essay'][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Curriculum has been adopted in many schools. This curriculum had a great impact on the developement of the children.But nowadays we see that the education institutions had tightened the curriculum system in such a manner that the children andyoung people arenot getting enough time to be indulged in other activities. Due to the strict and tightened rules the capacity of imagination and creativity isaffected badly.They become Book worm.A good curriculum is good for the children but apart from this same preference should be given to other activities.Following curriculum is necessary but education system have to understand the need of creativity and imagination role in a life of a person.There should a enough amount of curriculum should be prepared by the education systems that it will not affect the children and he or she will not feel the cumbersome of the theories.Due to the tightened curriculum thereb is no space left for the imagination and creativity. A creative mind is better than a mind full of notes and theories.Aenough space should be there for the development of the creativity in theminds of the children andyoung peoples.We all were aware of the saying thatcreativity leads to innovation.Educationplays a very vital role in the life of a person and it is that stage of life where a person grows and learn, if at that stage he or she will be engage by the theories and notes then it will going to affect their overall development. They may become mentally fit but the should not be able to delevop their thinking and creativity.So education system needs to losse the rope of curriculum and have to give equal preference to the other activities also.This will help children and young people toget enough time to increase their imagination power.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kEpvgIC4phd"
      },
      "source": [
        "\n",
        "from keras.models import load_model\n",
        "\n",
        "train_essays = X['essay']\n",
        "\n",
        "sentences = []\n",
        "\n",
        "for essay in train_essays:\n",
        "    # Obtaining all sentences from the training essays.\n",
        "    sentences += essay_to_sentences(essay, remove_stopwords = True)\n",
        "\n",
        "print(sentences)\n",
        "\n",
        "# Initializing variables for word2vec model.\n",
        "num_features = 300 \n",
        "min_word_count = 40\n",
        "num_workers = 4\n",
        "context = 10\n",
        "downsampling = 1e-3\n",
        "\n",
        "model = Word2Vec(sentences, workers=num_workers, size=num_features, min_count = min_word_count, window = context, sample = downsampling)\n",
        "\n",
        "#model.init_sims(replace=True)\n",
        "\n",
        "clean_train_essays = []\n",
        "\n",
        "# Generate training and testing data word vectors.\n",
        "for essay_v in train_essays:\n",
        "    clean_train_essays.append(essay_to_wordlist(essay_v, remove_stopwords=True))\n",
        "\n",
        "print(clean_train_essays)\n",
        "\n",
        "trainDataVecs = getAvgFeatureVecs(clean_train_essays, model, num_features)\n",
        "\n",
        "trainDataVecs = np.array(trainDataVecs)\n",
        "\n",
        "trainDataVecs = np.reshape(trainDataVecs, (trainDataVecs.shape[0], 1, trainDataVecs.shape[1]))\n",
        "\n",
        "print(trainDataVecs)\n",
        "\n",
        "lstm_model = load_model(\"final_lstm5.h5\")\n",
        "\n",
        "y_pred = lstm_model.predict(trainDataVecs)\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJIRUwLSJMXo",
        "outputId": "af352df8-d7bd-400f-ef3d-2ca58719ebfd"
      },
      "source": [
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "305"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cF5ZEFaQx5N"
      },
      "source": [
        "liist = []\n",
        "for i in range(0,304):\n",
        "    liist.append(np.round(y_pred[i][0]-2,2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TbYyJD4S9U9"
      },
      "source": [
        "import csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URIXLk52UQJh"
      },
      "source": [
        "X = pd.read_csv('test.csv', sep=',', encoding='ISO-8859-1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWKH8Un_SBEM"
      },
      "source": [
        "file = open(\"test_prediction.csv\", \"w\")\n",
        "writer = csv.writer(file)\n",
        "\n",
        "for w in range(0,304):\n",
        "\n",
        "    writer.writerow([X['promptId'][w],X['uniqueId'][w],X['essay'][w], liist[w]])\n",
        "\n",
        "file.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFk6wYfMQ2fb"
      },
      "source": [
        "liist"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}